{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY8OIQOIwl4O1K7BSyDE+c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MilanSinghBisht/collab-works/blob/main/part3(MNIST).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***FURTHER IMPROVING THE ARTIFICIAL NEURAL NETWORK IN TENSORFLOW WITH DROPOUT***"
      ],
      "metadata": {
        "id": "gSr-E5ePmOL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Pu6fu95xmdMQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#network and training\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES = 10\n",
        "N_HIDDEN =128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "DROPOUT = 0.3"
      ],
      "metadata": {
        "id": "G0rYs-hEmn55"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train,Y_train),(X_test,Y_test)= mnist.load_data()"
      ],
      "metadata": {
        "id": "Pz9i1_JNnBks"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESHAPED = 784\n",
        "X_train = X_train.reshape(60000,RESHAPED)\n",
        "X_test = X_test.reshape(10000,RESHAPED)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "metadata": {
        "id": "hgU0GyuFoSuZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normalizing inputs within [0,1]\n",
        "X_train,X_test = X_train / 255.0 ,X_test /255.0\n",
        "print(X_train.shape[0],'train samples')\n",
        "print(X_test.shape[0],'test samples')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N_EKVHhozp0",
        "outputId": "70c00647-dbee-48ca-ed8c-a75e1020744a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#one-hot\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)\n"
      ],
      "metadata": {
        "id": "drHvnfpXpmFG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building models\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "                input_shape = (RESHAPED,),\n",
        "                name = 'dense_layer',activation = 'relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(N_HIDDEN,\n",
        "                name = 'dense_layer_2',activation = 'relu'))\n",
        "model.add(keras.layers.Dropout(DROPOUT))\n",
        "model.add(keras.layers.Dense(NB_CLASSES,\n",
        "                name = 'dense_layer_3',activation = 'softmax'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xggB0y_spqc1",
        "outputId": "9d77ee57-0cee-4b31-9db3-7d59f745c98e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "KoKbkn-Cq5PR",
        "outputId": "86da5dd7-e42f-4796-cb3d-da05d1242c78"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compilation\n",
        "model.compile(optimizer = 'SGD',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RrPxOHydq9oS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training of the model\n",
        "model.fit(X_train,Y_train,\n",
        "          batch_size = BATCH_SIZE,epochs = EPOCHS,\n",
        "          verbose = VERBOSE,validation_split =VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKdRkV4crZr4",
        "outputId": "18d899c9-e4df-4131-9433-92cf6391bd2c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.3127 - loss: 2.0175 - val_accuracy: 0.8192 - val_loss: 0.9080\n",
            "Epoch 2/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.6883 - loss: 1.0225 - val_accuracy: 0.8700 - val_loss: 0.5367\n",
            "Epoch 3/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.7706 - loss: 0.7396 - val_accuracy: 0.8865 - val_loss: 0.4300\n",
            "Epoch 4/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8048 - loss: 0.6370 - val_accuracy: 0.8962 - val_loss: 0.3773\n",
            "Epoch 5/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.5594 - val_accuracy: 0.9027 - val_loss: 0.3437\n",
            "Epoch 6/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8495 - loss: 0.5078 - val_accuracy: 0.9091 - val_loss: 0.3196\n",
            "Epoch 7/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.4779 - val_accuracy: 0.9121 - val_loss: 0.3020\n",
            "Epoch 8/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8678 - loss: 0.4432 - val_accuracy: 0.9170 - val_loss: 0.2868\n",
            "Epoch 9/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8738 - loss: 0.4287 - val_accuracy: 0.9197 - val_loss: 0.2745\n",
            "Epoch 10/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8836 - loss: 0.4004 - val_accuracy: 0.9228 - val_loss: 0.2619\n",
            "Epoch 11/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8856 - loss: 0.3879 - val_accuracy: 0.9252 - val_loss: 0.2533\n",
            "Epoch 12/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3758 - val_accuracy: 0.9276 - val_loss: 0.2441\n",
            "Epoch 13/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.3573 - val_accuracy: 0.9305 - val_loss: 0.2363\n",
            "Epoch 14/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.3510 - val_accuracy: 0.9317 - val_loss: 0.2295\n",
            "Epoch 15/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9007 - loss: 0.3340 - val_accuracy: 0.9341 - val_loss: 0.2217\n",
            "Epoch 16/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8997 - loss: 0.3375 - val_accuracy: 0.9356 - val_loss: 0.2161\n",
            "Epoch 17/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.3144 - val_accuracy: 0.9370 - val_loss: 0.2106\n",
            "Epoch 18/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.3098 - val_accuracy: 0.9384 - val_loss: 0.2054\n",
            "Epoch 19/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.3024 - val_accuracy: 0.9393 - val_loss: 0.2010\n",
            "Epoch 20/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.2956 - val_accuracy: 0.9414 - val_loss: 0.1952\n",
            "Epoch 21/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2878 - val_accuracy: 0.9433 - val_loss: 0.1915\n",
            "Epoch 22/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2828 - val_accuracy: 0.9446 - val_loss: 0.1870\n",
            "Epoch 23/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9210 - loss: 0.2710 - val_accuracy: 0.9457 - val_loss: 0.1838\n",
            "Epoch 24/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9212 - loss: 0.2711 - val_accuracy: 0.9469 - val_loss: 0.1793\n",
            "Epoch 25/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9218 - loss: 0.2649 - val_accuracy: 0.9482 - val_loss: 0.1761\n",
            "Epoch 26/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9248 - loss: 0.2550 - val_accuracy: 0.9482 - val_loss: 0.1729\n",
            "Epoch 27/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9265 - loss: 0.2548 - val_accuracy: 0.9500 - val_loss: 0.1698\n",
            "Epoch 28/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9258 - loss: 0.2514 - val_accuracy: 0.9511 - val_loss: 0.1679\n",
            "Epoch 29/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9288 - loss: 0.2485 - val_accuracy: 0.9525 - val_loss: 0.1638\n",
            "Epoch 30/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9290 - loss: 0.2418 - val_accuracy: 0.9526 - val_loss: 0.1618\n",
            "Epoch 31/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9303 - loss: 0.2402 - val_accuracy: 0.9538 - val_loss: 0.1586\n",
            "Epoch 32/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9335 - loss: 0.2335 - val_accuracy: 0.9546 - val_loss: 0.1572\n",
            "Epoch 33/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9324 - loss: 0.2269 - val_accuracy: 0.9554 - val_loss: 0.1543\n",
            "Epoch 34/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9341 - loss: 0.2236 - val_accuracy: 0.9561 - val_loss: 0.1523\n",
            "Epoch 35/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9344 - loss: 0.2231 - val_accuracy: 0.9556 - val_loss: 0.1503\n",
            "Epoch 36/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9336 - loss: 0.2235 - val_accuracy: 0.9565 - val_loss: 0.1482\n",
            "Epoch 37/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9379 - loss: 0.2106 - val_accuracy: 0.9577 - val_loss: 0.1459\n",
            "Epoch 38/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9388 - loss: 0.2101 - val_accuracy: 0.9577 - val_loss: 0.1453\n",
            "Epoch 39/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9378 - loss: 0.2096 - val_accuracy: 0.9573 - val_loss: 0.1429\n",
            "Epoch 40/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9399 - loss: 0.2076 - val_accuracy: 0.9585 - val_loss: 0.1412\n",
            "Epoch 41/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9411 - loss: 0.2052 - val_accuracy: 0.9586 - val_loss: 0.1392\n",
            "Epoch 42/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9412 - loss: 0.2000 - val_accuracy: 0.9592 - val_loss: 0.1378\n",
            "Epoch 43/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9400 - loss: 0.2040 - val_accuracy: 0.9594 - val_loss: 0.1363\n",
            "Epoch 44/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9413 - loss: 0.1927 - val_accuracy: 0.9597 - val_loss: 0.1347\n",
            "Epoch 45/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9436 - loss: 0.1936 - val_accuracy: 0.9602 - val_loss: 0.1334\n",
            "Epoch 46/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1943 - val_accuracy: 0.9608 - val_loss: 0.1320\n",
            "Epoch 47/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.1900 - val_accuracy: 0.9610 - val_loss: 0.1296\n",
            "Epoch 48/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9473 - loss: 0.1824 - val_accuracy: 0.9612 - val_loss: 0.1297\n",
            "Epoch 49/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9456 - loss: 0.1796 - val_accuracy: 0.9615 - val_loss: 0.1278\n",
            "Epoch 50/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1876 - val_accuracy: 0.9614 - val_loss: 0.1267\n",
            "Epoch 51/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9469 - loss: 0.1805 - val_accuracy: 0.9620 - val_loss: 0.1256\n",
            "Epoch 52/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9472 - loss: 0.1780 - val_accuracy: 0.9626 - val_loss: 0.1245\n",
            "Epoch 53/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1768 - val_accuracy: 0.9628 - val_loss: 0.1235\n",
            "Epoch 54/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9463 - loss: 0.1816 - val_accuracy: 0.9630 - val_loss: 0.1221\n",
            "Epoch 55/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9489 - loss: 0.1734 - val_accuracy: 0.9627 - val_loss: 0.1215\n",
            "Epoch 56/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1731 - val_accuracy: 0.9638 - val_loss: 0.1200\n",
            "Epoch 57/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9492 - loss: 0.1733 - val_accuracy: 0.9637 - val_loss: 0.1189\n",
            "Epoch 58/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.1674 - val_accuracy: 0.9640 - val_loss: 0.1185\n",
            "Epoch 59/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1647 - val_accuracy: 0.9641 - val_loss: 0.1177\n",
            "Epoch 60/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.1659 - val_accuracy: 0.9643 - val_loss: 0.1167\n",
            "Epoch 61/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9522 - loss: 0.1611 - val_accuracy: 0.9641 - val_loss: 0.1169\n",
            "Epoch 62/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9528 - loss: 0.1626 - val_accuracy: 0.9647 - val_loss: 0.1149\n",
            "Epoch 63/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9520 - loss: 0.1623 - val_accuracy: 0.9647 - val_loss: 0.1148\n",
            "Epoch 64/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9526 - loss: 0.1614 - val_accuracy: 0.9650 - val_loss: 0.1134\n",
            "Epoch 65/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9544 - loss: 0.1583 - val_accuracy: 0.9657 - val_loss: 0.1130\n",
            "Epoch 66/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9543 - loss: 0.1519 - val_accuracy: 0.9655 - val_loss: 0.1127\n",
            "Epoch 67/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9554 - loss: 0.1529 - val_accuracy: 0.9669 - val_loss: 0.1120\n",
            "Epoch 68/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9560 - loss: 0.1540 - val_accuracy: 0.9668 - val_loss: 0.1107\n",
            "Epoch 69/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1505 - val_accuracy: 0.9669 - val_loss: 0.1097\n",
            "Epoch 70/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9560 - loss: 0.1486 - val_accuracy: 0.9672 - val_loss: 0.1091\n",
            "Epoch 71/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9547 - loss: 0.1527 - val_accuracy: 0.9669 - val_loss: 0.1088\n",
            "Epoch 72/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9548 - loss: 0.1508 - val_accuracy: 0.9671 - val_loss: 0.1081\n",
            "Epoch 73/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1522 - val_accuracy: 0.9670 - val_loss: 0.1076\n",
            "Epoch 74/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9562 - loss: 0.1474 - val_accuracy: 0.9675 - val_loss: 0.1073\n",
            "Epoch 75/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9577 - loss: 0.1457 - val_accuracy: 0.9678 - val_loss: 0.1064\n",
            "Epoch 76/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9591 - loss: 0.1398 - val_accuracy: 0.9681 - val_loss: 0.1059\n",
            "Epoch 77/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9563 - loss: 0.1424 - val_accuracy: 0.9681 - val_loss: 0.1055\n",
            "Epoch 78/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9573 - loss: 0.1436 - val_accuracy: 0.9685 - val_loss: 0.1048\n",
            "Epoch 79/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9567 - loss: 0.1420 - val_accuracy: 0.9682 - val_loss: 0.1047\n",
            "Epoch 80/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.1344 - val_accuracy: 0.9682 - val_loss: 0.1037\n",
            "Epoch 81/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9596 - loss: 0.1383 - val_accuracy: 0.9680 - val_loss: 0.1042\n",
            "Epoch 82/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1367 - val_accuracy: 0.9686 - val_loss: 0.1035\n",
            "Epoch 83/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9592 - loss: 0.1358 - val_accuracy: 0.9691 - val_loss: 0.1031\n",
            "Epoch 84/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.1331 - val_accuracy: 0.9703 - val_loss: 0.1018\n",
            "Epoch 85/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9606 - loss: 0.1332 - val_accuracy: 0.9698 - val_loss: 0.1016\n",
            "Epoch 86/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9603 - loss: 0.1354 - val_accuracy: 0.9697 - val_loss: 0.1013\n",
            "Epoch 87/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1332 - val_accuracy: 0.9698 - val_loss: 0.1007\n",
            "Epoch 88/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1303 - val_accuracy: 0.9704 - val_loss: 0.1008\n",
            "Epoch 89/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9607 - loss: 0.1323 - val_accuracy: 0.9704 - val_loss: 0.1002\n",
            "Epoch 90/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9599 - loss: 0.1333 - val_accuracy: 0.9702 - val_loss: 0.1000\n",
            "Epoch 91/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.1304 - val_accuracy: 0.9706 - val_loss: 0.0990\n",
            "Epoch 92/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9630 - loss: 0.1251 - val_accuracy: 0.9705 - val_loss: 0.0991\n",
            "Epoch 93/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9633 - loss: 0.1220 - val_accuracy: 0.9707 - val_loss: 0.0986\n",
            "Epoch 94/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.1222 - val_accuracy: 0.9712 - val_loss: 0.0979\n",
            "Epoch 95/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9614 - loss: 0.1295 - val_accuracy: 0.9711 - val_loss: 0.0974\n",
            "Epoch 96/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9629 - loss: 0.1231 - val_accuracy: 0.9708 - val_loss: 0.0970\n",
            "Epoch 97/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9637 - loss: 0.1201 - val_accuracy: 0.9716 - val_loss: 0.0967\n",
            "Epoch 98/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9632 - loss: 0.1206 - val_accuracy: 0.9715 - val_loss: 0.0967\n",
            "Epoch 99/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1213 - val_accuracy: 0.9712 - val_loss: 0.0959\n",
            "Epoch 100/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9630 - loss: 0.1233 - val_accuracy: 0.9713 - val_loss: 0.0964\n",
            "Epoch 101/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1233 - val_accuracy: 0.9717 - val_loss: 0.0952\n",
            "Epoch 102/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9649 - loss: 0.1169 - val_accuracy: 0.9716 - val_loss: 0.0958\n",
            "Epoch 103/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9635 - loss: 0.1247 - val_accuracy: 0.9721 - val_loss: 0.0953\n",
            "Epoch 104/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.1169 - val_accuracy: 0.9718 - val_loss: 0.0948\n",
            "Epoch 105/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9649 - loss: 0.1178 - val_accuracy: 0.9716 - val_loss: 0.0942\n",
            "Epoch 106/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9636 - loss: 0.1230 - val_accuracy: 0.9719 - val_loss: 0.0941\n",
            "Epoch 107/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1155 - val_accuracy: 0.9720 - val_loss: 0.0939\n",
            "Epoch 108/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9646 - loss: 0.1136 - val_accuracy: 0.9722 - val_loss: 0.0933\n",
            "Epoch 109/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9664 - loss: 0.1125 - val_accuracy: 0.9724 - val_loss: 0.0934\n",
            "Epoch 110/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9645 - loss: 0.1169 - val_accuracy: 0.9719 - val_loss: 0.0936\n",
            "Epoch 111/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9642 - loss: 0.1179 - val_accuracy: 0.9729 - val_loss: 0.0925\n",
            "Epoch 112/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9648 - loss: 0.1150 - val_accuracy: 0.9733 - val_loss: 0.0924\n",
            "Epoch 113/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9661 - loss: 0.1171 - val_accuracy: 0.9728 - val_loss: 0.0927\n",
            "Epoch 114/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9666 - loss: 0.1129 - val_accuracy: 0.9728 - val_loss: 0.0921\n",
            "Epoch 115/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9653 - loss: 0.1166 - val_accuracy: 0.9731 - val_loss: 0.0923\n",
            "Epoch 116/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.1136 - val_accuracy: 0.9734 - val_loss: 0.0915\n",
            "Epoch 117/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1123 - val_accuracy: 0.9732 - val_loss: 0.0912\n",
            "Epoch 118/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9681 - loss: 0.1090 - val_accuracy: 0.9730 - val_loss: 0.0910\n",
            "Epoch 119/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.1129 - val_accuracy: 0.9739 - val_loss: 0.0904\n",
            "Epoch 120/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9678 - loss: 0.1062 - val_accuracy: 0.9735 - val_loss: 0.0902\n",
            "Epoch 121/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.1109 - val_accuracy: 0.9737 - val_loss: 0.0905\n",
            "Epoch 122/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.1103 - val_accuracy: 0.9732 - val_loss: 0.0898\n",
            "Epoch 123/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9688 - loss: 0.1041 - val_accuracy: 0.9728 - val_loss: 0.0903\n",
            "Epoch 124/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.1097 - val_accuracy: 0.9737 - val_loss: 0.0891\n",
            "Epoch 125/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9689 - loss: 0.1027 - val_accuracy: 0.9732 - val_loss: 0.0894\n",
            "Epoch 126/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9692 - loss: 0.1020 - val_accuracy: 0.9742 - val_loss: 0.0892\n",
            "Epoch 127/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9694 - loss: 0.1019 - val_accuracy: 0.9741 - val_loss: 0.0890\n",
            "Epoch 128/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9701 - loss: 0.1001 - val_accuracy: 0.9738 - val_loss: 0.0891\n",
            "Epoch 129/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9685 - loss: 0.1028 - val_accuracy: 0.9737 - val_loss: 0.0887\n",
            "Epoch 130/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9676 - loss: 0.1027 - val_accuracy: 0.9743 - val_loss: 0.0887\n",
            "Epoch 131/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9681 - loss: 0.1060 - val_accuracy: 0.9741 - val_loss: 0.0882\n",
            "Epoch 132/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9700 - loss: 0.0983 - val_accuracy: 0.9742 - val_loss: 0.0880\n",
            "Epoch 133/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9683 - loss: 0.1019 - val_accuracy: 0.9739 - val_loss: 0.0881\n",
            "Epoch 134/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9700 - loss: 0.0987 - val_accuracy: 0.9740 - val_loss: 0.0876\n",
            "Epoch 135/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.0989 - val_accuracy: 0.9742 - val_loss: 0.0878\n",
            "Epoch 136/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.0990 - val_accuracy: 0.9746 - val_loss: 0.0874\n",
            "Epoch 137/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9697 - loss: 0.0997 - val_accuracy: 0.9743 - val_loss: 0.0874\n",
            "Epoch 138/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9696 - loss: 0.1013 - val_accuracy: 0.9742 - val_loss: 0.0871\n",
            "Epoch 139/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9711 - loss: 0.0931 - val_accuracy: 0.9746 - val_loss: 0.0868\n",
            "Epoch 140/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.0992 - val_accuracy: 0.9737 - val_loss: 0.0865\n",
            "Epoch 141/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9698 - loss: 0.0974 - val_accuracy: 0.9745 - val_loss: 0.0869\n",
            "Epoch 142/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9718 - loss: 0.0947 - val_accuracy: 0.9744 - val_loss: 0.0865\n",
            "Epoch 143/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9699 - loss: 0.0999 - val_accuracy: 0.9747 - val_loss: 0.0862\n",
            "Epoch 144/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9705 - loss: 0.0968 - val_accuracy: 0.9747 - val_loss: 0.0861\n",
            "Epoch 145/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.0962 - val_accuracy: 0.9748 - val_loss: 0.0861\n",
            "Epoch 146/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9705 - loss: 0.0944 - val_accuracy: 0.9747 - val_loss: 0.0859\n",
            "Epoch 147/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9717 - loss: 0.0951 - val_accuracy: 0.9748 - val_loss: 0.0858\n",
            "Epoch 148/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9695 - loss: 0.0975 - val_accuracy: 0.9748 - val_loss: 0.0854\n",
            "Epoch 149/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9712 - loss: 0.0957 - val_accuracy: 0.9747 - val_loss: 0.0855\n",
            "Epoch 150/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9706 - loss: 0.0968 - val_accuracy: 0.9746 - val_loss: 0.0854\n",
            "Epoch 151/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9733 - loss: 0.0887 - val_accuracy: 0.9753 - val_loss: 0.0855\n",
            "Epoch 152/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9732 - loss: 0.0926 - val_accuracy: 0.9746 - val_loss: 0.0853\n",
            "Epoch 153/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9718 - loss: 0.0900 - val_accuracy: 0.9746 - val_loss: 0.0853\n",
            "Epoch 154/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9730 - loss: 0.0895 - val_accuracy: 0.9753 - val_loss: 0.0849\n",
            "Epoch 155/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9719 - loss: 0.0933 - val_accuracy: 0.9750 - val_loss: 0.0849\n",
            "Epoch 156/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9726 - loss: 0.0915 - val_accuracy: 0.9753 - val_loss: 0.0851\n",
            "Epoch 157/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9724 - loss: 0.0937 - val_accuracy: 0.9753 - val_loss: 0.0848\n",
            "Epoch 158/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9722 - loss: 0.0908 - val_accuracy: 0.9754 - val_loss: 0.0845\n",
            "Epoch 159/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9741 - loss: 0.0869 - val_accuracy: 0.9750 - val_loss: 0.0845\n",
            "Epoch 160/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0892 - val_accuracy: 0.9757 - val_loss: 0.0847\n",
            "Epoch 161/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9739 - loss: 0.0867 - val_accuracy: 0.9748 - val_loss: 0.0843\n",
            "Epoch 162/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9728 - loss: 0.0858 - val_accuracy: 0.9758 - val_loss: 0.0845\n",
            "Epoch 163/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9729 - loss: 0.0875 - val_accuracy: 0.9752 - val_loss: 0.0836\n",
            "Epoch 164/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0868 - val_accuracy: 0.9758 - val_loss: 0.0837\n",
            "Epoch 165/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0844 - val_accuracy: 0.9753 - val_loss: 0.0848\n",
            "Epoch 166/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9734 - loss: 0.0855 - val_accuracy: 0.9760 - val_loss: 0.0842\n",
            "Epoch 167/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9740 - loss: 0.0834 - val_accuracy: 0.9758 - val_loss: 0.0836\n",
            "Epoch 168/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0815 - val_accuracy: 0.9757 - val_loss: 0.0838\n",
            "Epoch 169/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9719 - loss: 0.0896 - val_accuracy: 0.9751 - val_loss: 0.0836\n",
            "Epoch 170/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9746 - loss: 0.0813 - val_accuracy: 0.9757 - val_loss: 0.0835\n",
            "Epoch 171/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.0845 - val_accuracy: 0.9759 - val_loss: 0.0837\n",
            "Epoch 172/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9744 - loss: 0.0850 - val_accuracy: 0.9758 - val_loss: 0.0832\n",
            "Epoch 173/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9743 - loss: 0.0842 - val_accuracy: 0.9758 - val_loss: 0.0831\n",
            "Epoch 174/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0821 - val_accuracy: 0.9760 - val_loss: 0.0831\n",
            "Epoch 175/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9752 - loss: 0.0829 - val_accuracy: 0.9759 - val_loss: 0.0831\n",
            "Epoch 176/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9754 - loss: 0.0803 - val_accuracy: 0.9758 - val_loss: 0.0834\n",
            "Epoch 177/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0823 - val_accuracy: 0.9757 - val_loss: 0.0828\n",
            "Epoch 178/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9753 - loss: 0.0827 - val_accuracy: 0.9754 - val_loss: 0.0827\n",
            "Epoch 179/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9738 - loss: 0.0844 - val_accuracy: 0.9760 - val_loss: 0.0825\n",
            "Epoch 180/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0823 - val_accuracy: 0.9761 - val_loss: 0.0835\n",
            "Epoch 181/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.0828 - val_accuracy: 0.9758 - val_loss: 0.0825\n",
            "Epoch 182/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0826 - val_accuracy: 0.9759 - val_loss: 0.0827\n",
            "Epoch 183/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0799 - val_accuracy: 0.9758 - val_loss: 0.0827\n",
            "Epoch 184/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0806 - val_accuracy: 0.9756 - val_loss: 0.0826\n",
            "Epoch 185/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0751 - val_accuracy: 0.9758 - val_loss: 0.0823\n",
            "Epoch 186/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9749 - loss: 0.0805 - val_accuracy: 0.9753 - val_loss: 0.0820\n",
            "Epoch 187/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.0781 - val_accuracy: 0.9754 - val_loss: 0.0821\n",
            "Epoch 188/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0776 - val_accuracy: 0.9760 - val_loss: 0.0820\n",
            "Epoch 189/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0765 - val_accuracy: 0.9757 - val_loss: 0.0822\n",
            "Epoch 190/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9756 - loss: 0.0812 - val_accuracy: 0.9760 - val_loss: 0.0823\n",
            "Epoch 191/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0783 - val_accuracy: 0.9757 - val_loss: 0.0818\n",
            "Epoch 192/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0774 - val_accuracy: 0.9761 - val_loss: 0.0818\n",
            "Epoch 193/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9761 - loss: 0.0769 - val_accuracy: 0.9755 - val_loss: 0.0814\n",
            "Epoch 194/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9756 - loss: 0.0777 - val_accuracy: 0.9758 - val_loss: 0.0815\n",
            "Epoch 195/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0782 - val_accuracy: 0.9758 - val_loss: 0.0811\n",
            "Epoch 196/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0762 - val_accuracy: 0.9761 - val_loss: 0.0815\n",
            "Epoch 197/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9760 - loss: 0.0762 - val_accuracy: 0.9758 - val_loss: 0.0813\n",
            "Epoch 198/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9754 - loss: 0.0782 - val_accuracy: 0.9759 - val_loss: 0.0817\n",
            "Epoch 199/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9762 - loss: 0.0748 - val_accuracy: 0.9762 - val_loss: 0.0813\n",
            "Epoch 200/200\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9772 - loss: 0.0750 - val_accuracy: 0.9764 - val_loss: 0.0811\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d2528f0c510>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation\n",
        "test_loss,test_acc = model.evaluate(X_test,Y_test)\n",
        "print('test acccuracy',test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFMQQzxBuiUx",
        "outputId": "0d180468-c927-4e6b-a0e8-1078b89feac6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0924\n",
            "test acccuracy 0.9757000207901001\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0924\n",
            "test acccuracy 0.9757000207901001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BvicuGK6xzn1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}